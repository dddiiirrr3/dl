{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('data/restaurant.json')\n",
    "spam = pd.read_csv('data/spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>lDJIaF4eYRF4F7g6Zb9euw</td>\n",
       "      <td>lb0QUR5bc4O-Am4hNq9ZGg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I used to work food service and my manager at ...</td>\n",
       "      <td>2013-01-27 17:54:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>vvIzf3pr8lTqE_AOsxmgaA</td>\n",
       "      <td>MAmijW4ooUzujkufYYLMeQ</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We have been trying Eggplant sandwiches all ov...</td>\n",
       "      <td>2015-04-15 04:50:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>UF-JqzMczZ8vvp_4tPK3bQ</td>\n",
       "      <td>slfi6gf_qEYTXy90Sw93sg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazing Steak and Cheese... Better than any Ph...</td>\n",
       "      <td>2011-03-20 00:57:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>geUJGrKhXynxDC2uvERsLw</td>\n",
       "      <td>N_-UepOzAsuDQwOUtfRFGw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Although I have been going to DeFalco's for ye...</td>\n",
       "      <td>2018-07-17 01:48:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>aPctXPeZW3kDq36TRm-CqA</td>\n",
       "      <td>139hD7gkZVzSvSzDPwhNNw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highs: Ambience, value, pizza and deserts. Thi...</td>\n",
       "      <td>2018-01-21 10:52:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643007</th>\n",
       "      <td>0D__A1PkjvpG2pceebzLUA</td>\n",
       "      <td>H8E0U8CCaRA1mVJpd3mMDw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Just go here and eat all of things!  Penne a l...</td>\n",
       "      <td>2018-08-28 22:18:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644110</th>\n",
       "      <td>dsuz6EEsT_JphWTdE6rOew</td>\n",
       "      <td>iqXgKGWHGsF1uwczPBLd5g</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Went there for lunch today and it was sooo goo...</td>\n",
       "      <td>2018-11-10 02:14:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644370</th>\n",
       "      <td>7LROJHWjoq96I7Md8LIbQg</td>\n",
       "      <td>zGjZDf7ntd1SlIPCo5JhXg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Defalco' s the best in Scottsdale. Great sandw...</td>\n",
       "      <td>2015-02-14 23:51:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644531</th>\n",
       "      <td>yOLew_YdCmxpDDCdnm2Xgg</td>\n",
       "      <td>IQ8JZGg2po5YrcYqCBQQrw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>Defalco's is a great stop for all things Itali...</td>\n",
       "      <td>2018-05-24 20:31:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644757</th>\n",
       "      <td>dQqkQc_fpHtjqGimf3K2WQ</td>\n",
       "      <td>FLmu8E-MjRAM9YVllvt52A</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great, family like service.\\n\\nFrom NY, and it...</td>\n",
       "      <td>2008-08-12 21:17:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1321 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_id                 user_id  \\\n",
       "109     lDJIaF4eYRF4F7g6Zb9euw  lb0QUR5bc4O-Am4hNq9ZGg   \n",
       "1013    vvIzf3pr8lTqE_AOsxmgaA  MAmijW4ooUzujkufYYLMeQ   \n",
       "1204    UF-JqzMczZ8vvp_4tPK3bQ  slfi6gf_qEYTXy90Sw93sg   \n",
       "1251    geUJGrKhXynxDC2uvERsLw  N_-UepOzAsuDQwOUtfRFGw   \n",
       "1354    aPctXPeZW3kDq36TRm-CqA  139hD7gkZVzSvSzDPwhNNw   \n",
       "...                        ...                     ...   \n",
       "643007  0D__A1PkjvpG2pceebzLUA  H8E0U8CCaRA1mVJpd3mMDw   \n",
       "644110  dsuz6EEsT_JphWTdE6rOew  iqXgKGWHGsF1uwczPBLd5g   \n",
       "644370  7LROJHWjoq96I7Md8LIbQg  zGjZDf7ntd1SlIPCo5JhXg   \n",
       "644531  yOLew_YdCmxpDDCdnm2Xgg  IQ8JZGg2po5YrcYqCBQQrw   \n",
       "644757  dQqkQc_fpHtjqGimf3K2WQ  FLmu8E-MjRAM9YVllvt52A   \n",
       "\n",
       "                   business_id  stars  useful  funny  cool  \\\n",
       "109     r5PLDU-4mSbde5XekTXSCA      4       2      0     0   \n",
       "1013    r5PLDU-4mSbde5XekTXSCA      4       0      0     0   \n",
       "1204    r5PLDU-4mSbde5XekTXSCA      5       1      0     0   \n",
       "1251    r5PLDU-4mSbde5XekTXSCA      1       0      0     0   \n",
       "1354    r5PLDU-4mSbde5XekTXSCA      2       0      0     0   \n",
       "...                        ...    ...     ...    ...   ...   \n",
       "643007  r5PLDU-4mSbde5XekTXSCA      5       1      0     0   \n",
       "644110  r5PLDU-4mSbde5XekTXSCA      5       0      0     0   \n",
       "644370  r5PLDU-4mSbde5XekTXSCA      5       0      0     0   \n",
       "644531  r5PLDU-4mSbde5XekTXSCA      4      20      9    16   \n",
       "644757  r5PLDU-4mSbde5XekTXSCA      4       0      0     0   \n",
       "\n",
       "                                                     text                date  \n",
       "109     I used to work food service and my manager at ... 2013-01-27 17:54:54  \n",
       "1013    We have been trying Eggplant sandwiches all ov... 2015-04-15 04:50:56  \n",
       "1204    Amazing Steak and Cheese... Better than any Ph... 2011-03-20 00:57:45  \n",
       "1251    Although I have been going to DeFalco's for ye... 2018-07-17 01:48:23  \n",
       "1354    Highs: Ambience, value, pizza and deserts. Thi... 2018-01-21 10:52:58  \n",
       "...                                                   ...                 ...  \n",
       "643007  Just go here and eat all of things!  Penne a l... 2018-08-28 22:18:29  \n",
       "644110  Went there for lunch today and it was sooo goo... 2018-11-10 02:14:12  \n",
       "644370  Defalco' s the best in Scottsdale. Great sandw... 2015-02-14 23:51:41  \n",
       "644531  Defalco's is a great stop for all things Itali... 2018-05-24 20:31:21  \n",
       "644757  Great, family like service.\\n\\nFrom NY, and it... 2008-08-12 21:17:00  \n",
       "\n",
       "[1321 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
    "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \n",
    "         \"Prosciutto\", \"Salami\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id                                 lDJIaF4eYRF4F7g6Zb9euw\n",
       "user_id                                   lb0QUR5bc4O-Am4hNq9ZGg\n",
       "business_id                               r5PLDU-4mSbde5XekTXSCA\n",
       "stars                                                          4\n",
       "useful                                                         2\n",
       "funny                                                          0\n",
       "cool                                                           0\n",
       "text           I used to work food service and my manager at ...\n",
       "date                                         2013-01-27 17:54:54\n",
       "Name: 109, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_review_to_test_on = 14\n",
    "text_to_test_on = data.text.iloc[index_of_review_to_test_on]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spacy model\n",
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tokenized version of text_to_test_on\n",
    "review_doc = nlp(text_to_test_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PhraseMatcher object. The tokenizer is the first argument. use attr = 'LOWER' to make consistent capitalization\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tokens for each item in the menu\n",
    "menu_tokens_list = [nlp(item) for item in menu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the item patterns to the matcher\n",
    "\n",
    "matcher.add('MENU',          # just a name for the set of rules we're matching to\n",
    "            None,            # special actions to take on matched words\n",
    "            *menu_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find matches in the review_doc\n",
    "matches = matcher(review_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8291075388056826051, 2, 3),\n",
       " (8291075388056826051, 16, 17),\n",
       " (8291075388056826051, 58, 59)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token number 2: Purista\n",
      "Token number 16: prosciutto\n",
      "Token number 58: meatball\n"
     ]
    }
   ],
   "source": [
    "for match in matches:\n",
    "    print(f'Token number {match[1]}: {review_doc[match[1]:match[2]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_ratings is a dictionary of lists. if a key doesn't exist in item_ratings,\n",
    "# the key is added with an empty list as the value\n",
    "item_ratings = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(item_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, review in data.iterrows():\n",
    "    \n",
    "    doc = nlp(review.text)\n",
    "    \n",
    "    # using the matcher from the previous exercise\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # create a set of the items found in the review text\n",
    "    found_items = set([doc[match[1]:match[2]] for match in matches])\n",
    "    \n",
    "    # update item_ratings with rating for each item in found_items\n",
    "    # transform the item strings to lowercase to make it case insensitive\n",
    "    for item in found_items:\n",
    "        item_ratings[str(item).lower()].append(review.stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [key for key in item_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([np.mean(item_ratings[key]) for key in [key for key in item_ratings]]).idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicken cutlet'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {item: len(ratings) for item, ratings in item_ratings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = sorted(counts, key=counts.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    pizza  358\n",
      "                    pasta  255\n",
      "                 meatball  163\n",
      "              cheesesteak  146\n",
      "                  calzone  110\n",
      "                 eggplant   95\n",
      "                  cannoli   89\n",
      "             cheese steak   88\n",
      "                  lasagna   83\n",
      "                  purista   67\n",
      "               prosciutto   63\n",
      "             chicken parm   58\n",
      "          italian sausage   57\n",
      "             garlic bread   46\n",
      "                  gnocchi   45\n",
      "                spaghetti   41\n",
      "                 calzones   38\n",
      "                   pizzas   33\n",
      "                   salami   32\n",
      "            chicken pesto   30\n",
      "             italian beef   29\n",
      "                 tiramisu   27\n",
      "                     ziti   26\n",
      "            italian combo   22\n",
      "         chicken parmesan   21\n",
      "       chicken parmigiana   18\n",
      "           mac and cheese   18\n",
      "               portobello   18\n",
      "                 pastrami   16\n",
      "           chicken cutlet   11\n",
      "         steak and cheese    9\n",
      "               roast beef    7\n",
      "       fettuccini alfredo    6\n",
      "           grilled veggie    6\n",
      "                 macaroni    6\n",
      "            chicken salad    6\n",
      "               tuna salad    5\n",
      "          turkey sandwich    5\n",
      "          artichoke salad    5\n",
      "                   reuben    5\n",
      "    chicken spinach salad    2\n",
      "              corned beef    2\n",
      "            turkey breast    1\n",
      "                        1    0\n",
      "                        2    0\n",
      "                       21    0\n"
     ]
    }
   ],
   "source": [
    "for item in item_counts:\n",
    "    print(f'{item:>25}{counts[item]:>5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-07c8c3a72931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Worst rated menu items:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_ratings' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_ratings = sorted(mean_ratings, key=mean_ratings.get)\n",
    "\n",
    "print(\"Worst rated menu items:\")\n",
    "for item in sorted_ratings[:10]:\n",
    "    print(f\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\")\n",
    "    \n",
    "print(\"\\n\\nBest rated menu items:\")\n",
    "for item in sorted_ratings[-10:]:\n",
    "    print(f\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Tea is healthy and calming, don't you think?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tea\n",
      "is\n",
      "healthy\n",
      "and\n",
      "calming\n",
      ",\n",
      "do\n",
      "n't\n",
      "you\n",
      "think\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token \t\tLemma \t\tStopword\n",
      "----------------------------------------\n",
      "Tea\t\ttea\t\tFalse\n",
      "is\t\tbe\t\tTrue\n",
      "healthy\t\thealthy\t\tFalse\n",
      "and\t\tand\t\tTrue\n",
      "calming\t\tcalm\t\tFalse\n",
      ",\t\t,\t\tFalse\n",
      "do\t\tdo\t\tTrue\n",
      "n't\t\tnot\t\tTrue\n",
      "you\t\t-PRON-\t\tTrue\n",
      "think\t\tthink\t\tFalse\n",
      "?\t\t?\t\tFalse\n"
     ]
    }
   ],
   "source": [
    "print(f'Token \\t\\tLemma \\t\\tStopword'.format('Token', 'Lemma', 'Stopword'))\n",
    "print('-'*40)\n",
    "for token in doc:\n",
    "    print(f'{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\n",
    "patterns = [nlp(text) for text in terms]\n",
    "matcher.add('TerminologyList', None, *patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3766102292120407359, 17, 19), (3766102292120407359, 22, 24), (3766102292120407359, 30, 32), (3766102292120407359, 33, 35)]\n"
     ]
    }
   ],
   "source": [
    "text_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n",
    "               \"photography tests pitting the iPhone 11 Pro against the \"\n",
    "               \"Galaxy Note 10 Plus and last yearâ€™s iPhone XS and Google Pixel 3.\")\n",
    "matches = matcher(text_doc)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TerminologyList iPhone 11\n"
     ]
    }
   ],
   "source": [
    "match_id, start, end = matches[0]\n",
    "print(nlp.vocab.strings[match_id], text_doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ÃŒ_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will ÃŒ_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty model\n",
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the TextCategorizer with exclusive classes and 'bow' architecture\n",
    "textcat = nlp.create_pipe('textcat', config={'exclusive_classes': True, \n",
    "                                             'architecture': 'bow'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the TextCategorizer to the empty model\n",
    "nlp.add_pipe(textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add labels to text classifier\n",
    "textcat.add_label('ham')\n",
    "textcat.add_label('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = spam['text'].values\n",
    "train_labels = [{'cats': {'ham': label == 'ham',\n",
    "                          'spam': label == 'spam'}}\n",
    "                for label in spam['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "  {'cats': {'ham': True, 'spam': False}}),\n",
       " ('Ok lar... Joking wif u oni...', {'cats': {'ham': True, 'spam': False}}),\n",
       " (\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "  {'cats': {'ham': False, 'spam': True}}),\n",
       " ('U dun say so early hor... U c already then say...',\n",
       "  {'cats': {'ham': True, 'spam': False}}),\n",
       " (\"Nah I don't think he goes to usf, he lives around here though\",\n",
       "  {'cats': {'ham': True, 'spam': False}})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = list(zip(train_texts, train_labels))\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch\n",
    "\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the batch generator with batch size = 8\n",
    "batches = minibatch(train_data, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through minibatches\n",
    "for batch in batches:\n",
    "    # Each batch is a list of (text, label) but we need to\n",
    "    # send separate lists for texts and labels to update().\n",
    "    # This is a quick way to split a list of tuples into lists\n",
    "    texts, labels = zip(*batch)\n",
    "    nlp.update(texts, labels, sgd=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 0.4318974211906266}\n",
      "{'textcat': 0.6474976200079823}\n",
      "{'textcat': 0.7842154482108383}\n",
      "{'textcat': 0.871668365141693}\n",
      "{'textcat': 0.9280939272314639}\n",
      "{'textcat': 0.9655779823256229}\n",
      "{'textcat': 0.9939651726794686}\n",
      "{'textcat': 1.0127976501288052}\n",
      "{'textcat': 1.0275637671914504}\n",
      "{'textcat': 1.0378531321124917}\n"
     ]
    }
   ],
   "source": [
    "losses = {}\n",
    "for epoch in range(10):\n",
    "    random.shuffle(train_data)\n",
    "    # create the batch generator with batch size = 8\n",
    "    batches = minibatch(train_data, size=8)\n",
    "    # iterate through minibatches\n",
    "    for batch in batches:\n",
    "        # each batch is a list of (text, label) but we need to\n",
    "        # send separate lists for texts and labels to update().\n",
    "        # this is a quick way to split a list of tuples into lists\n",
    "        texts, labels = zip(*batch)\n",
    "        nlp.update(texts, labels, sgd=optimizer, losses=losses)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9996209e-01 3.7902697e-05]\n",
      " [1.1491313e-02 9.8850864e-01]]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Are you ready fot the tea party????? It's gonna be wild\",\n",
    "         \"URGENT Reply to this message for GUARANTEED FREE TEA\"]\n",
    "docs = [nlp.tokenizer(text) for text in texts]\n",
    "\n",
    "# use textcat to get the scores for each doc\n",
    "textcat = nlp.get_pipe('textcat')\n",
    "scores, _ = textcat.predict(docs)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', 'spam']\n"
     ]
    }
   ],
   "source": [
    "# from the scores, find the label with the highest score/probability\n",
    "predicted_labels = scores.argmax(axis=1)\n",
    "print([textcat.labels[label] for label in predicted_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
